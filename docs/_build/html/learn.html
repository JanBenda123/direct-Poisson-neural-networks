<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>learn &#8212; Direct Poisson Neural Networks 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=4f649999" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=039e1c02" />
    <script src="_static/documentation_options.js?v=f2a433a1"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Models" href="models.html" />
    <link rel="prev" title="plot_compare.py" href="plot_compare.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="module-learn">
<span id="learn"></span><h1>learn<a class="headerlink" href="#module-learn" title="Link to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="learn.Learner">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">learn.</span></span><span class="sig-name descname"><span class="pre">Learner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neurons</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dissipative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.Learner" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This is the fundamental class that provides the capability to learn dynamical systems,
using various methods of learning (without Jacobi identity, with softly enforced Jacobi, and with implicitly valid Jacobi).</p>
<dl class="py method">
<dt class="sig sig-object py" id="learn.Learner.mov_loss_without">
<span class="sig-name descname"><span class="pre">mov_loss_without</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.Learner.mov_loss_without" title="Link to this definition">¶</a></dt>
<dd><p>The function calculates the movement loss using the “without” method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The <cite>zn_tensor</cite> parameter represents the current state of the system. It is a tensor that contains the values of the variables in the system at a particular time</p></li>
<li><p><strong>zn2_tensor</strong> – The parameter <cite>zn2_tensor</cite> is a tensor representing the current state of the system at time <cite>t+dt</cite>. It is used to calculate the loss function for the movement of the system without considering any external forces or constraints</p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter is not used in the <cite>mov_loss_without</cite> function. It is not necessary for the calculation and can be removed from the function signature</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the result of the expression <cite>(zn_tensor - zn2_tensor)/self.dt + 1.0/2.0*(torch.matmul(Lz, E_z.unsqueeze(2)).squeeze() + torch.matmul(Lz2, E_z2.unsqueeze(2)).squeeze())</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.Learner.mov_loss_without_with_jacobi">
<span class="sig-name descname"><span class="pre">mov_loss_without_with_jacobi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduced_L</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.Learner.mov_loss_without_with_jacobi" title="Link to this definition">¶</a></dt>
<dd><p>The function calculates the movement loss including Jacobi identity the for a given input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The zn_tensor is a tensor representing the current state of the system. It is used to calculate the energy and the Jacobian loss of the system</p></li>
<li><p><strong>zn2_tensor</strong> – The <cite>zn2_tensor</cite> parameter is a tensor representing the state at time <cite>t+1</cite>. It is used to calculate the loss for the movement of the system without using the Jacobian matrix</p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter is a tensor representing the intermediate state between <cite>zn_tensor</cite> and <cite>zn2_tensor</cite>. It is used to calculate the loss function</p></li>
<li><p><strong>reduced_L</strong> – The parameter “reduced_L” is a reduced Laplacian matrix. It is used in the calculation of the Jacobi loss</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>two values: 1. The difference between <cite>zn_tensor</cite> and <cite>zn2_tensor</cite> divided by <cite>self.dt</cite> plus half of the sum of the matrix multiplication of <cite>Lz</cite> and <cite>E_z</cite> and the matrix multiplication of <cite>Lz2</cite> and <cite>E_z2</cite>. 2. The <cite>jacobi_loss</cite> calculated using <cite>zn_tensor</cite>, `</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.Learner.jacobi_loss">
<span class="sig-name descname"><span class="pre">jacobi_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Lz</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduced_L</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.Learner.jacobi_loss" title="Link to this definition">¶</a></dt>
<dd><p>The function <cite>jacobi_loss</cite> calculates the Jacobi loss (error in Jacobi identity) using the given inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The <cite>zn_tensor</cite> parameter is a tensor representing the input to the function. It is used to compute the Jacobian loss.</p></li>
<li><p><strong>Lz</strong> – Lz is a tensor representing the Jacobian matrix of the output with respect to the input. It has shape (m, n, n), where m is the number of samples and n is the number of input variables.</p></li>
<li><p><strong>reduced_L</strong> – The parameter <cite>reduced_L</cite> is a tensor representing the reduced loss function</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the sum of three terms: term1, term2, and term3.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.Learner.mov_loss_soft">
<span class="sig-name descname"><span class="pre">mov_loss_soft</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduced_L</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.Learner.mov_loss_soft" title="Link to this definition">¶</a></dt>
<dd><p>The function <cite>mov_loss_soft</cite> calculates the movement loss and Jacobi loss for a given input tensor, using the “soft” method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The zn_tensor is a tensor representing the current state of the system. It is used to calculate the energy and gradient of the energy with respect to zn_tensor</p></li>
<li><p><strong>zn2_tensor</strong> – The <cite>zn2_tensor</cite> parameter is a tensor representing the state at time <cite>t+1</cite>. It is used to calculate the movement loss and Jacobi loss in the <cite>mov_loss_soft</cite> function</p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter is not used in the <cite>mov_loss_soft</cite> function. It is not clear what its purpose is without further context.</p></li>
<li><p><strong>reduced_L</strong> – The parameter “reduced_L” is a tensor representing the reduced Laplacian matrix</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>two values: <cite>mov_loss</cite> and <cite>jacobi_loss</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.Learner.mov_loss_implicit">
<span class="sig-name descname"><span class="pre">mov_loss_implicit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.Learner.mov_loss_implicit" title="Link to this definition">¶</a></dt>
<dd><p>The function <cite>mov_loss_implicit</cite> calculates the loss for a motion model using the “implicit” method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The <cite>zn_tensor</cite> parameter is a tensor representing the current state of the system. It is used to calculate the energy and Jacobian vectors for the system.</p></li>
<li><p><strong>zn2_tensor</strong> – The <cite>zn2_tensor</cite> parameter is a tensor representing the state of the system at time <cite>t + dt</cite>, where <cite>t</cite> is the current time and <cite>dt</cite> is the time step.</p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter is not used in the <cite>mov_loss_implicit</cite> function. It is not necessary for the calculation and can be removed from the function signature.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The function <cite>mov_loss_implicit</cite> returns the result of the expression <cite>(zn_tensor - zn2_tensor)/self.dt + 1.0/2.0*(torch.cross(Jz, E_z, dim=1) + torch.cross(Jz2, E_z2, dim=1))</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.Learner.learn">
<span class="sig-name descname"><span class="pre">learn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'without'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prefactor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jac_prefactor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'IMR'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.Learner.learn" title="Link to this definition">¶</a></dt>
<dd><p>The <cite>learn</cite> function is used to train a model using different methods and parameters, and it saves
the trained models and error metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> – The method parameter determines the learning method to be used. It can take one of three values: “without”, “soft”, or “implicit”, defaults to without (optional)</p></li>
<li><p><strong>learning_rate</strong> – The learning rate determines the step size at which the optimizer adjusts the model’s parameters during training. It controls how quickly or slowly the model learns from the training data</p></li>
<li><p><strong>epochs</strong> – The “epochs” parameter determines the number of times the model will iterate over the entire training dataset during the learning process. Each iteration is called an epoch</p></li>
<li><p><strong>prefactor</strong> – The <cite>prefactor</cite> parameter is a scaling factor that is applied to the movement loss during training. It allows you to control the relative importance of the movement loss compared to other losses or metrics. By adjusting the value of <cite>prefactor</cite>, you can increase or decrease the impact of the movement loss on</p></li>
<li><p><strong>jac_prefactor</strong> – The <cite>jac_prefactor</cite> parameter is used as a scaling factor for the regularization term in the loss function. It determines the relative importance of the regularization term compared to the movement term in the loss function. A higher value of <cite>jac_prefactor</cite> will give more weight to the regularization term, while</p></li>
<li><p><strong>scheme</strong> – The “scheme” parameter is a string that specifies the numerical scheme used for solving the equations. It can take one of the following values:, defaults to IMR (optional)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="learn.LearnerIMR">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">learn.</span></span><span class="sig-name descname"><span class="pre">LearnerIMR</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neurons</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">64</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'.'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dissipative</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.LearnerIMR" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#learn.Learner" title="learn.Learner"><code class="xref py py-class docutils literal notranslate"><span class="pre">Learner</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="learn.LearnerIMR.mov_loss_without">
<span class="sig-name descname"><span class="pre">mov_loss_without</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.LearnerIMR.mov_loss_without" title="Link to this definition">¶</a></dt>
<dd><p>The function calculates the loss for a given input tensor by computing the energy, and then combining them with other tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The <cite>zn_tensor</cite> parameter is a tensor representing the current state of the system</p></li>
<li><p><strong>zn2_tensor</strong> – The <cite>zn2_tensor</cite> parameter is a tensor representing the state at time <cite>t-2*dt</cite></p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter is a tensor representing the intermediate state of the system. It is used to compute various quantities such as energy (<cite>En</cite>), and the gradient of energy (<cite>E_z</cite>) with respect to <cite>mid_tensor</cite>. These quantities</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>returns <cite>(zn_tensor - zn2_tensor)/self.dt + ham</cite>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.LearnerIMR.mov_loss_without_with_jacobi">
<span class="sig-name descname"><span class="pre">mov_loss_without_with_jacobi</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduced_L</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.LearnerIMR.mov_loss_without_with_jacobi" title="Link to this definition">¶</a></dt>
<dd><p>The function calculates the moving loss and Jacobi loss for given tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The zn_tensor is a tensor representing the current state of the system. It is used as input to calculate the mov_loss and jacobi_loss</p></li>
<li><p><strong>zn2_tensor</strong> – The <cite>zn2_tensor</cite> parameter is a tensor representing the second frame of a video sequence</p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter is a tensor that represents the intermediate state of the model during training. It is typically used to calculate losses or perform other operations</p></li>
<li><p><strong>reduced_L</strong> – The parameter “reduced_L” is a reduced version of the L tensor. It is used in the calculation of the Jacobi loss</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>two values: mov_loss and jacobi_loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.LearnerIMR.mov_loss_soft">
<span class="sig-name descname"><span class="pre">mov_loss_soft</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduced_L</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.LearnerIMR.mov_loss_soft" title="Link to this definition">¶</a></dt>
<dd><p>The function calculates the moving loss and Jacobi loss for a given set of tensors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The zn_tensor is a tensor representing the first set of input data for the mov_loss_soft function</p></li>
<li><p><strong>zn2_tensor</strong> – The <cite>zn2_tensor</cite> parameter is a tensor representing the second zero-normalized tensor</p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter is a tensor that represents the intermediate output of a neural network model. It is used as input to calculate the moving loss and Jacobi loss</p></li>
<li><p><strong>reduced_L</strong> – The parameter “reduced_L” is a reduced version of the L tensor. It is used in the calculation of the Jacobi loss</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>two values: mov_loss and jacobi_loss.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="learn.LearnerIMR.mov_loss_implicit">
<span class="sig-name descname"><span class="pre">mov_loss_implicit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">zn_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">zn2_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mid_tensor</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.LearnerIMR.mov_loss_implicit" title="Link to this definition">¶</a></dt>
<dd><p>The function calculates the implicit loss for a given input tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>zn_tensor</strong> – The <cite>zn_tensor</cite> parameter represents the current state of the system at time <cite>n</cite></p></li>
<li><p><strong>zn2_tensor</strong> – The <cite>zn2_tensor</cite> parameter is a tensor representing the state at time <cite>t - dt</cite></p></li>
<li><p><strong>mid_tensor</strong> – The <cite>mid_tensor</cite> parameter represents the input tensor for which the energy and Jacobian vectors are calculated</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>the result of the expression <cite>(zn_tensor - zn2_tensor)/self.dt + torch.cross(Jz, E_z, dim=1)</cite>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="learn.check_folder">
<span class="sig-prename descclassname"><span class="pre">learn.</span></span><span class="sig-name descname"><span class="pre">check_folder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#learn.check_folder" title="Link to this definition">¶</a></dt>
<dd><p>The function <cite>check_folder</cite> checks if the specified folder exists, and if not, creates it along with
two subfolders named “data” and “saved_models”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> – The <cite>name</cite> parameter is the name of the folder that you want to check and create if it doesn’t exist</p>
</dd>
</dl>
</dd></dl>

</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">Direct Poisson Neural Networks</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="comparison.html">comparison.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="plot_compare.html">plot_compare.py</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="simulate.html">simualte.py</a></li>
<li class="toctree-l1"><a class="reference internal" href="TrajectoryDataset.html">TrajectoryDataset.py</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="plot_compare.html" title="previous chapter">plot_compare.py</a></li>
      <li>Next: <a href="models.html" title="next chapter">Models</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Martin Šípka, Michal Pavelka, Oğul Esen, and Miroslav Grmela.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/learn.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>